{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Labels\n",
    "\n",
    "Code to build dataframes that contain directory listings of train, test and validate extracted JPEG frames including labels  \n",
    "Code to build dataframes that contain directory listings of train, test and validate extracted avi videos including labels  \n",
    "Assumed working from DAiSEE dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is predominantly for CNN, or models where the order of imgaes does not matter (i.e. not RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Project/src/cnn'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = '1FPS'\n",
    "frame_dir = '../../data/DAiSEE/' + fps + '/dataImages/'\n",
    "label_path = '../../data/DAiSEE/Labels/'\n",
    "out_dir = '../../data/DAiSEE/' + fps + '/data/' \n",
    "\n",
    "usage = ['Train', 'Test', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels (frame_dir, usage):\n",
    "    df_l = pd.read_csv(label_path + usage + 'Labels.csv')\n",
    "    df_l['basename'] = df_l['ClipID'].str[:-4]\n",
    "    \n",
    "    # Get Data Files\n",
    "    df_j = pd.DataFrame([file_path for file_path in Path(frame_dir + usage).glob('*.jpg')], columns=['file'])\n",
    "    df_j[\"root\"] = df_j[\"file\"].apply(lambda x: os.path.split(os.path.split(x)[0])[1])\n",
    "    df_j['basefile'] = df_j['file'].apply(lambda x: os.path.basename(x))\n",
    "    df_j['sequence'] = df_j['basefile'].apply(lambda x: int(x[x.find('_')+1:-4]))\n",
    "    df_j['basename'] = df_j['basefile'].apply(lambda x: x[:x.find('_')])  \n",
    "    \n",
    "    # Merge and cleanup\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')  \n",
    "        \n",
    "    df.rename(columns={'Frustration ':'Frustration'}, inplace = True)   \n",
    "    df['file'] = df['file'].apply(lambda x: str(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_labels(frame_dir, 'Train')\n",
    "df_test = get_labels(frame_dir, 'Test')\n",
    "df_val = get_labels(frame_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53580, 10)\n",
      "(17840, 10)\n",
      "(14290, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to pickle in case we need it later\n",
    "df_train.to_pickle(frame_dir + \"/df_train.pkl\")\n",
    "df_test.to_pickle(frame_dir + \"/df_test.pkl\")\n",
    "df_val.to_pickle(frame_dir + \"/df_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arrays(df, usage):\n",
    "    np.random.seed(100)\n",
    "    indices = np.random.permutation(len(df['file']))\n",
    " \n",
    "    filepath = df['file'].to_numpy()\n",
    "    filepath = filepath[indices]\n",
    "    label = np.array(df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]) \n",
    "    label = label[indices]\n",
    "\n",
    "    np.save(f\"{str(frame_dir)}/x_{usage.lower()}\", filepath, allow_pickle=True)\n",
    "    np.save(f\"{str(frame_dir)}/y_{usage.lower()}\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays(df_train, 'train')\n",
    "save_arrays(df_test, 'test')\n",
    "save_arrays(df_val, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move files to appropriate directories (train, test, val)\n",
    "\n",
    "### Create Class Subdirectories for ease of use with Tenrorflow datasets\n",
    "\n",
    "Inititally treat as a binary problem (cannot be a bit engaged and a bit bored  \n",
    "Therefore create a binary class column based on boredom  \n",
    "If there are duplicated we are going to keep going, because one less image file should not make a difference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_encoder(df):\n",
    "    y = pd.get_dummies(df['Boredom'], prefix='b')\n",
    "    df = pd.concat([df,y], axis = 1)\n",
    "    df.rename(columns={\"b_0\": \"b0\", \"b_1\": \"b1\", \"b_2\": \"b2\", \"b_3\": \"b3\"}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = class_encoder(df_train)\n",
    "df_test = class_encoder(df_test)\n",
    "df_val = class_encoder(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to copy images to correct file structure\n",
    "# As we have some duplicate file names, instead of fixing we will ignore as we have more than enough images\n",
    "def copy_files(source, destination):\n",
    "    for f in source:\n",
    "        destination_file = os.path.join(destination, os.path.basename(f))\n",
    "        shutil.copy(os.fspath(f), destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image file structure for bored/not bored and copy files\n",
    "cols = ['b0', 'b1', 'b2', 'b3']\n",
    "dirs = ['train', 'test', 'validation']\n",
    "\n",
    "for d in dirs:\n",
    "    for c in cols:\n",
    "        data_dir = out_dir + '/' + d + '/' + c\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/DAiSEE/1FPS/data/\n"
     ]
    }
   ],
   "source": [
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Train Images\n",
    "copy_files(df_train[df_train['b0']==1]['file'].to_list(), out_dir + 'train/b0/')\n",
    "copy_files(df_train[df_train['b1']==1]['file'].to_list(), out_dir + 'train/b1/')\n",
    "copy_files(df_train[df_train['b2']==1]['file'].to_list(), out_dir + 'train/b2/')\n",
    "copy_files(df_train[df_train['b3']==1]['file'].to_list(), out_dir + 'train/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Test Images\n",
    "copy_files(df_test[df_test['b0']==1]['file'].to_list(), out_dir + '/test/b0/')\n",
    "copy_files(df_test[df_test['b1']==1]['file'].to_list(), out_dir + '/test/b1/')\n",
    "copy_files(df_test[df_test['b2']==1]['file'].to_list(), out_dir + '/test/b2/')\n",
    "copy_files(df_test[df_test['b3']==1]['file'].to_list(), out_dir + '/test/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Validation Images\n",
    "copy_files(df_val[df_val['b0']==1]['file'].to_list(), out_dir + '/validation/b0/')\n",
    "copy_files(df_val[df_val['b1']==1]['file'].to_list(), out_dir + '/validation/b1/')\n",
    "copy_files(df_val[df_val['b2']==1]['file'].to_list(), out_dir + '/validation/b2/')\n",
    "copy_files(df_val[df_val['b3']==1]['file'].to_list(), out_dir + '/validation/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
