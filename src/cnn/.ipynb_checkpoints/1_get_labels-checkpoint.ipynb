{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Labels\n",
    "\n",
    "Code to build dataframes that contain directory listings of train, test and validate extracted JPEG frames including labels  \n",
    "Code to build dataframes that contain directory listings of train, test and validate extracted avi videos including labels  \n",
    "Assumed working from DAiSEE dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chris/MIDS/w251/w251_ChrisSexton/Project/src/cnn'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = '2FPS'\n",
    "frame_dir = '../../data/DAiSEE/' + fps + '/dataImages/'\n",
    "label_path = '../../data/DAiSEE/Labels/'\n",
    "out_dir = '../../data/DAiSEE/' + fps + '/data/' \n",
    "\n",
    "usage = ['Train', 'Test', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels (frame_dir, usage):\n",
    "    df_l = pd.read_csv(label_path + usage + 'Labels.csv')\n",
    "    df_l['basename'] = df_l['ClipID'].str[:-4]\n",
    "    \n",
    "    # Get Data Files\n",
    "    df_j = pd.DataFrame([file_path for file_path in Path(frame_dir + usage).glob('*.jpg')], columns=['file'])\n",
    "    df_j[\"root\"] = df_j[\"file\"].apply(lambda x: os.path.split(os.path.split(x)[0])[1])\n",
    "    df_j['basefile'] = df_j['file'].apply(lambda x: os.path.basename(x))\n",
    "    df_j['sequence'] = df_j['basefile'].apply(lambda x: int(x[x.find('_')+1:-4]))\n",
    "    df_j['basename'] = df_j['basefile'].apply(lambda x: x[:x.find('_')])  \n",
    "    \n",
    "    # Merge and cleanup\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')  \n",
    "        \n",
    "    df.rename(columns={'Frustration ':'Frustration'}, inplace = True)   \n",
    "    df['file'] = df['file'].apply(lambda x: str(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_labels(frame_dir, 'Train')\n",
    "df_test = get_labels(frame_dir, 'Test')\n",
    "df_val = get_labels(frame_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9500\n",
       "0    8920\n",
       "1    7520\n",
       "3    2640\n",
       "Name: Boredom, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Boredom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to pickle in case we need it later\n",
    "df_train.to_pickle(frame_dir + \"/df_train.pkl\")\n",
    "df_test.to_pickle(frame_dir + \"/df_test.pkl\")\n",
    "df_val.to_pickle(frame_dir + \"/df_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107140, 14)\n",
      "(35680, 14)\n",
      "(28580, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_14.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_15.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_17.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107135</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210061...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100611005_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2100611005</td>\n",
       "      <td>2100611005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107136</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210061...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100611005_10.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>2100611005</td>\n",
       "      <td>2100611005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107137</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210061...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100611005_12.jpg</td>\n",
       "      <td>12</td>\n",
       "      <td>2100611005</td>\n",
       "      <td>2100611005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107138</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210061...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100611005_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2100611005</td>\n",
       "      <td>2100611005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107139</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210061...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100611005_13.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>2100611005</td>\n",
       "      <td>2100611005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107140 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     file   root  \\\n",
       "0       ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "1       ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "2       ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "3       ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "4       ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "...                                                   ...    ...   \n",
       "107135  ../../data/DAiSEE/2FPS/dataImages/Train/210061...  Train   \n",
       "107136  ../../data/DAiSEE/2FPS/dataImages/Train/210061...  Train   \n",
       "107137  ../../data/DAiSEE/2FPS/dataImages/Train/210061...  Train   \n",
       "107138  ../../data/DAiSEE/2FPS/dataImages/Train/210061...  Train   \n",
       "107139  ../../data/DAiSEE/2FPS/dataImages/Train/210061...  Train   \n",
       "\n",
       "                 basefile  sequence    basename          ClipID  Boredom  \\\n",
       "0        2100592066_1.jpg         1  2100592066  2100592066.avi        1   \n",
       "1       2100592066_14.jpg        14  2100592066  2100592066.avi        1   \n",
       "2       2100592066_15.jpg        15  2100592066  2100592066.avi        1   \n",
       "3       2100592066_17.jpg        17  2100592066  2100592066.avi        1   \n",
       "4        2100592066_2.jpg         2  2100592066  2100592066.avi        1   \n",
       "...                   ...       ...         ...             ...      ...   \n",
       "107135   2100611005_2.jpg         2  2100611005  2100611005.avi        0   \n",
       "107136  2100611005_10.jpg        10  2100611005  2100611005.avi        0   \n",
       "107137  2100611005_12.jpg        12  2100611005  2100611005.avi        0   \n",
       "107138   2100611005_1.jpg         1  2100611005  2100611005.avi        0   \n",
       "107139  2100611005_13.jpg        13  2100611005  2100611005.avi        0   \n",
       "\n",
       "        Engagement  Confusion  Frustration  b0  b1  b2  b3  \n",
       "0                2          0            0   0   1   0   0  \n",
       "1                2          0            0   0   1   0   0  \n",
       "2                2          0            0   0   1   0   0  \n",
       "3                2          0            0   0   1   0   0  \n",
       "4                2          0            0   0   1   0   0  \n",
       "...            ...        ...          ...  ..  ..  ..  ..  \n",
       "107135           2          0            0   1   0   0   0  \n",
       "107136           2          0            0   1   0   0   0  \n",
       "107137           2          0            0   1   0   0   0  \n",
       "107138           2          0            0   1   0   0   0  \n",
       "107139           2          0            0   1   0   0   0  \n",
       "\n",
       "[107140 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arrays(df, usage):\n",
    "    filepath = df['file'].to_numpy()\n",
    "    label = np.array(df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]) \n",
    "\n",
    "    np.save(f\"{str(frame_dir)}/x_{usage.lower()}\", filepath, allow_pickle=True)\n",
    "    np.save(f\"{str(frame_dir)}/y_{usage.lower()}\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays(df_train, 'train')\n",
    "save_arrays(df_test, 'test')\n",
    "save_arrays(df_val, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move files to appropriate directories (train, test, val)\n",
    "\n",
    "### Create Class Subdirectories for ease of use with Tenrorflow datasets\n",
    "\n",
    "Inititally treat as a binary problem (cannot be a bit engaged and a bit bored  \n",
    "Therefore create a binary class column based on boredom  \n",
    "If there are duplicated we are going to keep going, because one less image file should not make a difference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_encoder(df):\n",
    "    y = pd.get_dummies(df['Boredom'], prefix='b')\n",
    "    df = pd.concat([df,y], axis = 1)\n",
    "    df.rename(columns={\"b_0\": \"b0\", \"b_1\": \"b1\", \"b_2\": \"b2\", \"b_3\": \"b3\"}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = class_encoder(df_train)\n",
    "df_test = class_encoder(df_test)\n",
    "df_val = class_encoder(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boredom\n",
       "0    8920\n",
       "1    7520\n",
       "2    9500\n",
       "3    2640\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values for 'Boredom'\n",
    "df_val.groupby(['Boredom']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to copy images to correct file structure\n",
    "# As we have some duplicate file names, instead of fixing we will ignore as we have more than enough images\n",
    "def copy_files(source, destination):\n",
    "    for f in source:\n",
    "        destination_file = os.path.join(destination, os.path.basename(f))\n",
    "        shutil.copy(os.fspath(f), destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image file structure for bored/not bored and copy files\n",
    "cols = ['b0', 'b1', 'b2', 'b3']\n",
    "dirs = ['train', 'test', 'validation']\n",
    "\n",
    "for d in dirs:\n",
    "    for c in cols:\n",
    "        data_dir = out_dir + '/' + d + '/' + c\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/DAiSEE/2FPS/data/\n"
     ]
    }
   ],
   "source": [
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Train Images\n",
    "copy_files(df_train[df_train['b0']==1]['file'].to_list(), out_dir + 'train/b0/')\n",
    "copy_files(df_train[df_train['b1']==1]['file'].to_list(), out_dir + 'train/b1/')\n",
    "copy_files(df_train[df_train['b2']==1]['file'].to_list(), out_dir + 'train/b2/')\n",
    "copy_files(df_train[df_train['b3']==1]['file'].to_list(), out_dir + 'train/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Test Images\n",
    "copy_files(df_test[df_test['b0']==1]['file'].to_list(), out_dir + '/test/b0/')\n",
    "copy_files(df_test[df_test['b1']==1]['file'].to_list(), out_dir + '/test/b1/')\n",
    "copy_files(df_test[df_test['b2']==1]['file'].to_list(), out_dir + '/test/b2/')\n",
    "copy_files(df_test[df_test['b3']==1]['file'].to_list(), out_dir + '/test/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Validation Images\n",
    "copy_files(df_val[df_val['b0']==1]['file'].to_list(), out_dir + '/validation/b0/')\n",
    "copy_files(df_val[df_val['b1']==1]['file'].to_list(), out_dir + '/validation/b1/')\n",
    "copy_files(df_val[df_val['b2']==1]['file'].to_list(), out_dir + '/validation/b2/')\n",
    "copy_files(df_val[df_val['b3']==1]['file'].to_list(), out_dir + '/validation/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
