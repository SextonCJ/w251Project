{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to take 2FPS data and make sure there is an exactly 20 Frames for each video\n",
    "# This is for whole image only, not faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = '2FPS'\n",
    "frame_dir = '../../data/DAiSEE/' + fps + '/dataImages/'\n",
    "label_path = '../../data/DAiSEE/Labels/'\n",
    "out_dir = '../../data/DAiSEE/' + fps + '/data/' \n",
    "\n",
    "usage = ['Train', 'Test', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels (frame_dir, usage):\n",
    "    df_l = pd.read_csv(label_path + usage + 'Labels.csv')\n",
    "    df_l['basename'] = df_l['ClipID'].str[:-4]\n",
    "    \n",
    "    # Get Data Files\n",
    "    df_j = pd.DataFrame([file_path for file_path in Path(frame_dir + usage).glob('*.jpg')], columns=['file'])\n",
    "    df_j[\"root\"] = df_j[\"file\"].apply(lambda x: os.path.split(os.path.split(x)[0])[1])\n",
    "    df_j['basefile'] = df_j['file'].apply(lambda x: os.path.basename(x))\n",
    "    df_j['sequence'] = df_j['basefile'].apply(lambda x: int(x[x.find('_')+1:-4]))\n",
    "    df_j['basename'] = df_j['basefile'].apply(lambda x: x[:x.find('_')])  \n",
    "    \n",
    "    # Merge and cleanup\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')  \n",
    "        \n",
    "    df.rename(columns={'Frustration ':'Frustration'}, inplace = True)   \n",
    "    df['file'] = df['file'].apply(lambda x: str(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_labels(frame_dir, 'Train')\n",
    "df_test = get_labels(frame_dir, 'Test')\n",
    "df_val = get_labels(frame_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9500\n",
       "0    8920\n",
       "1    7520\n",
       "3    2640\n",
       "Name: Boredom, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Boredom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107253, 10)\n",
      "(35757, 10)\n",
      "(28580, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/310080...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3100802001_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3100802001</td>\n",
       "      <td>3100802001.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/310080...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3100802001_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3100802001</td>\n",
       "      <td>3100802001.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/310080...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3100802001_3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3100802001</td>\n",
       "      <td>3100802001.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/310080...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3100802001_4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>3100802001</td>\n",
       "      <td>3100802001.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/310080...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3100802001_5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>3100802001</td>\n",
       "      <td>3100802001.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file   root          basefile  \\\n",
       "0  ../../data/DAiSEE/2FPS/dataImages/Train/310080...  Train  3100802001_1.jpg   \n",
       "1  ../../data/DAiSEE/2FPS/dataImages/Train/310080...  Train  3100802001_2.jpg   \n",
       "2  ../../data/DAiSEE/2FPS/dataImages/Train/310080...  Train  3100802001_3.jpg   \n",
       "3  ../../data/DAiSEE/2FPS/dataImages/Train/310080...  Train  3100802001_4.jpg   \n",
       "4  ../../data/DAiSEE/2FPS/dataImages/Train/310080...  Train  3100802001_5.jpg   \n",
       "\n",
       "   sequence    basename          ClipID  Boredom  Engagement  Confusion  \\\n",
       "0         1  3100802001  3100802001.avi        0           3          0   \n",
       "1         2  3100802001  3100802001.avi        0           3          0   \n",
       "2         3  3100802001  3100802001.avi        0           3          0   \n",
       "3         4  3100802001  3100802001.avi        0           3          0   \n",
       "4         5  3100802001  3100802001.avi        0           3          0   \n",
       "\n",
       "   Frustration  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file path and name)\n",
    "df_train.sort_values([\"basename\", \"sequence\"], inplace = True)    \n",
    "df_test.sort_values([\"basename\", \"sequence\"], inplace = True)   \n",
    "df_val.sort_values([\"basename\", \"sequence\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file   root  \\\n",
       "10900  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "10901  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "10902  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "10903  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "10904  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "\n",
       "               basefile  sequence    basename          ClipID  Boredom  \\\n",
       "10900  1100011002_1.jpg         1  1100011002  1100011002.avi        0   \n",
       "10901  1100011002_2.jpg         2  1100011002  1100011002.avi        0   \n",
       "10902  1100011002_3.jpg         3  1100011002  1100011002.avi        0   \n",
       "10903  1100011002_4.jpg         4  1100011002  1100011002.avi        0   \n",
       "10904  1100011002_5.jpg         5  1100011002  1100011002.avi        0   \n",
       "\n",
       "       Engagement  Confusion  Frustration  \n",
       "10900           2          0            0  \n",
       "10901           2          0            0  \n",
       "10902           2          0            0  \n",
       "10903           2          0            0  \n",
       "10904           2          0            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_files(file_list):\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resequence the faces\n",
    "df_train['frame_seq']=df_train.groupby('basename').cumcount()\n",
    "df_test['frame_seq']=df_test.groupby('basename').cumcount()\n",
    "df_val['frame_seq']=df_val.groupby('basename').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20\n",
      "test 20\n",
      "val 20\n"
     ]
    }
   ],
   "source": [
    "# check minimum number of frames per basename again - should be 20\n",
    "print(\"train\", df_train.groupby(['basename']).size().min())\n",
    "print(\"test\",df_test.groupby(['basename']).size().min())\n",
    "print(\"val\",df_val.groupby(['basename']).size().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basename</th>\n",
       "      <th>frame_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [basename, frame_seq]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the file whereby the max number of frames is 19\n",
    "# we are going to delete so that we have exactly 20 frames\n",
    "df_tmp = df_train.groupby('basename')['frame_seq'].max().to_frame().reset_index()\n",
    "df_tmp[\"frame_seq\"] = pd.to_numeric(df_tmp[\"frame_seq\"])\n",
    "df_tmp[df_tmp[\"frame_seq\"]<19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete from filesystem whatever showed up in above query\n",
    "#del_short_files = df_train[df_train['basename']=='2100552061']['file'].to_list()\n",
    "#del_files(del_short_files)\n",
    "# delete from dataframe\n",
    "#df_train.drop(df_train[df_train['basename'] == '2100552061'].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Remove just the files that are too long, i.e. more than 20 frames\n",
    "\n",
    "# get list of files and delete\n",
    "train_del_files = df_train[df_train['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(train_del_files)\n",
    "\n",
    "test_del_files = df_test[df_test['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(test_del_files)\n",
    "\n",
    "val_del_files = df_val[df_val['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(val_del_files)\n",
    "\n",
    "# remove from dataframe\n",
    "df_train.drop(df_train[df_train['frame_seq'] > 19].index, inplace = True) \n",
    "df_test.drop(df_test[df_test['frame_seq'] > 19].index, inplace = True) \n",
    "df_val.drop(df_val[df_val['frame_seq'] > 19].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20\n",
      "test 20\n",
      "val 20\n"
     ]
    }
   ],
   "source": [
    "# check minimum number of frames per basename again - should now be 20\n",
    "print(\"train\", df_train.groupby(['basename']).size().min())\n",
    "print(\"test\",df_test.groupby(['basename']).size().min())\n",
    "print(\"val\",df_val.groupby(['basename']).size().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indexes\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "      <th>frame_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file   root          basefile  \\\n",
       "0  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_1.jpg   \n",
       "1  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_2.jpg   \n",
       "2  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_3.jpg   \n",
       "3  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_4.jpg   \n",
       "4  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_5.jpg   \n",
       "\n",
       "   sequence    basename          ClipID  Boredom  Engagement  Confusion  \\\n",
       "0         1  1100011002  1100011002.avi        0           2          0   \n",
       "1         2  1100011002  1100011002.avi        0           2          0   \n",
       "2         3  1100011002  1100011002.avi        0           2          0   \n",
       "3         4  1100011002  1100011002.avi        0           2          0   \n",
       "4         5  1100011002  1100011002.avi        0           2          0   \n",
       "\n",
       "   Frustration  frame_seq  \n",
       "0            0          0  \n",
       "1            0          1  \n",
       "2            0          2  \n",
       "3            0          3  \n",
       "4            0          4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all the dataframes are in order and all the files are in order \n",
    "# we can resave the dataframe for future use\n",
    "df_train.to_pickle(frame_dir + \"/df_train.pkl\")\n",
    "df_test.to_pickle(frame_dir + \"/df_test.pkl\")\n",
    "df_val.to_pickle(frame_dir + \"/df_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Arrays (do not shuffle)\n",
    "def save_arrays(df, usage): \n",
    "    filepath = df['file'].to_numpy()\n",
    "    label = np.array(df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]) \n",
    "\n",
    "    np.save(f\"{str(frame_dir)}/x_{usage.lower()}\", filepath, allow_pickle=True)\n",
    "    np.save(f\"{str(frame_dir)}/y_{usage.lower()}\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays(df_train, 'train')\n",
    "save_arrays(df_test, 'test')\n",
    "save_arrays(df_val, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW COPY TO BOREDOM DIRECTORIES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_encoder(df):\n",
    "    y = pd.get_dummies(df['Boredom'], prefix='b')\n",
    "    df = pd.concat([df,y], axis = 1)\n",
    "    df.rename(columns={\"b_0\": \"b0\", \"b_1\": \"b1\", \"b_2\": \"b2\", \"b_3\": \"b3\"}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = class_encoder(df_train)\n",
    "df_test = class_encoder(df_test)\n",
    "df_val = class_encoder(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107160, 15) divided by 20= 5358.0\n",
      "(35680, 15) divided by 20= 1784.0\n",
      "(28580, 15) divided by 20= 1429.0\n"
     ]
    }
   ],
   "source": [
    "# check shapes of df - they should all be divisible by 20\n",
    "print(df_train.shape, 'divided by 20=', df_train.shape[0]/20)\n",
    "print(df_test.shape, 'divided by 20=', df_test.shape[0]/20)\n",
    "print(df_val.shape, 'divided by 20=', df_val.shape[0]/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to copy images to correct file structure\n",
    "# As we have some duplicate file names, instead of fixing we will ignore as we have more than enough images\n",
    "def copy_files(source, destination):\n",
    "    for f in source:\n",
    "        destination_file = os.path.join(destination, os.path.basename(f))\n",
    "        shutil.copy(os.fspath(f), destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image file structure for bored/not bored and copy files\n",
    "cols = ['b0', 'b1', 'b2', 'b3']\n",
    "dirs = ['train', 'test', 'validation']\n",
    "\n",
    "for d in dirs:\n",
    "    for c in cols:\n",
    "        data_dir = out_dir + '/' + d + '/' + c\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/DAiSEE/2FPS/data/\n"
     ]
    }
   ],
   "source": [
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Train Images\n",
    "copy_files(df_train[df_train['b0']==1]['file'].to_list(), out_dir + 'train/b0/')\n",
    "copy_files(df_train[df_train['b1']==1]['file'].to_list(), out_dir + 'train/b1/')\n",
    "copy_files(df_train[df_train['b2']==1]['file'].to_list(), out_dir + 'train/b2/')\n",
    "copy_files(df_train[df_train['b3']==1]['file'].to_list(), out_dir + 'train/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Test Images\n",
    "copy_files(df_test[df_test['b0']==1]['file'].to_list(), out_dir + '/test/b0/')\n",
    "copy_files(df_test[df_test['b1']==1]['file'].to_list(), out_dir + '/test/b1/')\n",
    "copy_files(df_test[df_test['b2']==1]['file'].to_list(), out_dir + '/test/b2/')\n",
    "copy_files(df_test[df_test['b3']==1]['file'].to_list(), out_dir + '/test/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Validation Images\n",
    "copy_files(df_val[df_val['b0']==1]['file'].to_list(), out_dir + '/validation/b0/')\n",
    "copy_files(df_val[df_val['b1']==1]['file'].to_list(), out_dir + '/validation/b1/')\n",
    "copy_files(df_val[df_val['b2']==1]['file'].to_list(), out_dir + '/validation/b2/')\n",
    "copy_files(df_val[df_val['b3']==1]['file'].to_list(), out_dir + '/validation/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
