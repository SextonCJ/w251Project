{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to take 2FPS data and make sure there is an exactly 20 Frames for each video\n",
    "# This is for whole image only, not faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = '2FPS'\n",
    "frame_dir = '../../data/DAiSEE/' + fps + '/dataImages/'\n",
    "label_path = '../../data/DAiSEE/Labels/'\n",
    "out_dir = '../../data/DAiSEE/' + fps + '/data/' \n",
    "\n",
    "usage = ['Train', 'Test', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels (frame_dir, usage):\n",
    "    df_l = pd.read_csv(label_path + usage + 'Labels.csv')\n",
    "    df_l['basename'] = df_l['ClipID'].str[:-4]\n",
    "    \n",
    "    # Get Data Files\n",
    "    df_j = pd.DataFrame([file_path for file_path in Path(frame_dir + usage).glob('*.jpg')], columns=['file'])\n",
    "    df_j[\"root\"] = df_j[\"file\"].apply(lambda x: os.path.split(os.path.split(x)[0])[1])\n",
    "    df_j['basefile'] = df_j['file'].apply(lambda x: os.path.basename(x))\n",
    "    df_j['sequence'] = df_j['basefile'].apply(lambda x: int(x[x.find('_')+1:-4]))\n",
    "    df_j['basename'] = df_j['basefile'].apply(lambda x: x[:x.find('_')])  \n",
    "    \n",
    "    # Merge and cleanup\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')\n",
    "    df = pd.merge(df_j, df_l, on='basename', how='inner')  \n",
    "        \n",
    "    df.rename(columns={'Frustration ':'Frustration'}, inplace = True)   \n",
    "    df['file'] = df['file'].apply(lambda x: str(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_labels(frame_dir, 'Train')\n",
    "df_test = get_labels(frame_dir, 'Test')\n",
    "df_val = get_labels(frame_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9500\n",
       "0    8920\n",
       "1    7520\n",
       "3    2640\n",
       "Name: Boredom, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Boredom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107140, 10)\n",
      "(35680, 10)\n",
      "(28580, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_14.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_15.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_17.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/210059...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2100592066_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2100592066</td>\n",
       "      <td>2100592066.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file   root  \\\n",
       "0  ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "1  ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "2  ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "3  ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "4  ../../data/DAiSEE/2FPS/dataImages/Train/210059...  Train   \n",
       "\n",
       "            basefile  sequence    basename          ClipID  Boredom  \\\n",
       "0   2100592066_1.jpg         1  2100592066  2100592066.avi        1   \n",
       "1  2100592066_14.jpg        14  2100592066  2100592066.avi        1   \n",
       "2  2100592066_15.jpg        15  2100592066  2100592066.avi        1   \n",
       "3  2100592066_17.jpg        17  2100592066  2100592066.avi        1   \n",
       "4   2100592066_2.jpg         2  2100592066  2100592066.avi        1   \n",
       "\n",
       "   Engagement  Confusion  Frustration  \n",
       "0           2          0            0  \n",
       "1           2          0            0  \n",
       "2           2          0            0  \n",
       "3           2          0            0  \n",
       "4           2          0            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file path and name)\n",
    "df_train.sort_values([\"basename\", \"sequence\"], inplace = True)    \n",
    "df_test.sort_values([\"basename\", \"sequence\"], inplace = True)   \n",
    "df_val.sort_values([\"basename\", \"sequence\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87024</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87023</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87020</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87026</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87025</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file   root  \\\n",
       "87024  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "87023  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "87020  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "87026  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "87025  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train   \n",
       "\n",
       "               basefile  sequence    basename          ClipID  Boredom  \\\n",
       "87024  1100011002_1.jpg         1  1100011002  1100011002.avi        0   \n",
       "87023  1100011002_2.jpg         2  1100011002  1100011002.avi        0   \n",
       "87020  1100011002_3.jpg         3  1100011002  1100011002.avi        0   \n",
       "87026  1100011002_4.jpg         4  1100011002  1100011002.avi        0   \n",
       "87025  1100011002_5.jpg         5  1100011002  1100011002.avi        0   \n",
       "\n",
       "       Engagement  Confusion  Frustration  \n",
       "87024           2          0            0  \n",
       "87023           2          0            0  \n",
       "87020           2          0            0  \n",
       "87026           2          0            0  \n",
       "87025           2          0            0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_files(file_list):\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resequence the faces\n",
    "df_train['frame_seq']=df_train.groupby('basename').cumcount()\n",
    "df_test['frame_seq']=df_test.groupby('basename').cumcount()\n",
    "df_val['frame_seq']=df_val.groupby('basename').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20\n",
      "test 20\n",
      "val 20\n"
     ]
    }
   ],
   "source": [
    "# check minimum number of frames per basename again - should be 20\n",
    "print(\"train\", df_train.groupby(['basename']).size().min())\n",
    "print(\"test\",df_test.groupby(['basename']).size().min())\n",
    "print(\"val\",df_val.groupby(['basename']).size().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basename</th>\n",
       "      <th>frame_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [basename, frame_seq]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the file whereby the max number of frames is 19\n",
    "# we are going to delete so that we have exactly 20 frames\n",
    "df_tmp = df_train.groupby('basename')['frame_seq'].max().to_frame().reset_index()\n",
    "df_tmp[\"frame_seq\"] = pd.to_numeric(df_tmp[\"frame_seq\"])\n",
    "df_tmp[df_tmp[\"frame_seq\"]<19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete from filesystem\n",
    "del_short_files = df_train[df_train['basename']=='2100552061']['file'].to_list()\n",
    "del_files(del_short_files)\n",
    "# delete from dataframe\n",
    "df_train.drop(df_train[df_train['basename'] == '2100552061'].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Remove just the files that are too long, i.e. more than 20 frames\n",
    "\n",
    "# get list of files and delete\n",
    "train_del_files = df_train[df_train['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(train_del_files)\n",
    "\n",
    "test_del_files = df_test[df_test['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(test_del_files)\n",
    "\n",
    "val_del_files = df_val[df_val['frame_seq'] > 19]['file'].to_list()\n",
    "del_files(val_del_files)\n",
    "\n",
    "# remove from dataframe\n",
    "df_train.drop(df_train[df_train['frame_seq'] > 19].index, inplace = True) \n",
    "df_test.drop(df_test[df_test['frame_seq'] > 19].index, inplace = True) \n",
    "df_val.drop(df_val[df_val['frame_seq'] > 19].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20\n",
      "test 20\n",
      "val 20\n"
     ]
    }
   ],
   "source": [
    "# check minimum number of frames per basename again - should now be 20\n",
    "print(\"train\", df_train.groupby(['basename']).size().min())\n",
    "print(\"test\",df_test.groupby(['basename']).size().min())\n",
    "print(\"val\",df_val.groupby(['basename']).size().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indexes\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>root</th>\n",
       "      <th>basefile</th>\n",
       "      <th>sequence</th>\n",
       "      <th>basename</th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "      <th>frame_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/DAiSEE/2FPS/dataImages/Train/110001...</td>\n",
       "      <td>Train</td>\n",
       "      <td>1100011002_5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>1100011002</td>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file   root          basefile  \\\n",
       "0  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_1.jpg   \n",
       "1  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_2.jpg   \n",
       "2  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_3.jpg   \n",
       "3  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_4.jpg   \n",
       "4  ../../data/DAiSEE/2FPS/dataImages/Train/110001...  Train  1100011002_5.jpg   \n",
       "\n",
       "   sequence    basename          ClipID  Boredom  Engagement  Confusion  \\\n",
       "0         1  1100011002  1100011002.avi        0           2          0   \n",
       "1         2  1100011002  1100011002.avi        0           2          0   \n",
       "2         3  1100011002  1100011002.avi        0           2          0   \n",
       "3         4  1100011002  1100011002.avi        0           2          0   \n",
       "4         5  1100011002  1100011002.avi        0           2          0   \n",
       "\n",
       "   Frustration  frame_seq  \n",
       "0            0          0  \n",
       "1            0          1  \n",
       "2            0          2  \n",
       "3            0          3  \n",
       "4            0          4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all the dataframes are in order and all the files are in order \n",
    "# we can resave the dataframe for future use\n",
    "df_train.to_pickle(frame_dir + \"/df_train.pkl\")\n",
    "df_test.to_pickle(frame_dir + \"/df_test.pkl\")\n",
    "df_val.to_pickle(frame_dir + \"/df_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Arrays (do not shuffle)\n",
    "def save_arrays(df, usage): \n",
    "    filepath = df['file'].to_numpy()\n",
    "    label = np.array(df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]) \n",
    "\n",
    "    np.save(f\"{str(frame_dir)}/x_{usage.lower()}\", filepath, allow_pickle=True)\n",
    "    np.save(f\"{str(frame_dir)}/y_{usage.lower()}\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays(df_train, 'train')\n",
    "save_arrays(df_test, 'test')\n",
    "save_arrays(df_val, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW COPY TO BOREDOM DIRECTORIES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_encoder(df):\n",
    "    y = pd.get_dummies(df['Boredom'], prefix='b')\n",
    "    df = pd.concat([df,y], axis = 1)\n",
    "    df.rename(columns={\"b_0\": \"b0\", \"b_1\": \"b1\", \"b_2\": \"b2\", \"b_3\": \"b3\"}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = class_encoder(df_train)\n",
    "df_test = class_encoder(df_test)\n",
    "df_val = class_encoder(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boredom\n",
       "0    8920\n",
       "1    7520\n",
       "2    9500\n",
       "3    2640\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values for 'Boredom'\n",
    "df_val.groupby(['Boredom']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to copy images to correct file structure\n",
    "# As we have some duplicate file names, instead of fixing we will ignore as we have more than enough images\n",
    "def copy_files(source, destination):\n",
    "    for f in source:\n",
    "        destination_file = os.path.join(destination, os.path.basename(f))\n",
    "        shutil.copy(os.fspath(f), destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image file structure for bored/not bored and copy files\n",
    "cols = ['b0', 'b1', 'b2', 'b3']\n",
    "dirs = ['train', 'test', 'validation']\n",
    "\n",
    "for d in dirs:\n",
    "    for c in cols:\n",
    "        data_dir = out_dir + '/' + d + '/' + c\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/DAiSEE/2FPS/data/\n"
     ]
    }
   ],
   "source": [
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Train Images\n",
    "copy_files(df_train[df_train['b0']==1]['file'].to_list(), out_dir + 'train/b0/')\n",
    "copy_files(df_train[df_train['b1']==1]['file'].to_list(), out_dir + 'train/b1/')\n",
    "copy_files(df_train[df_train['b2']==1]['file'].to_list(), out_dir + 'train/b2/')\n",
    "copy_files(df_train[df_train['b3']==1]['file'].to_list(), out_dir + 'train/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Test Images\n",
    "copy_files(df_test[df_test['b0']==1]['file'].to_list(), out_dir + '/test/b0/')\n",
    "copy_files(df_test[df_test['b1']==1]['file'].to_list(), out_dir + '/test/b1/')\n",
    "copy_files(df_test[df_test['b2']==1]['file'].to_list(), out_dir + '/test/b2/')\n",
    "copy_files(df_test[df_test['b3']==1]['file'].to_list(), out_dir + '/test/b3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Validation Images\n",
    "copy_files(df_val[df_val['b0']==1]['file'].to_list(), out_dir + '/validation/b0/')\n",
    "copy_files(df_val[df_val['b1']==1]['file'].to_list(), out_dir + '/validation/b1/')\n",
    "copy_files(df_val[df_val['b2']==1]['file'].to_list(), out_dir + '/validation/b2/')\n",
    "copy_files(df_val[df_val['b3']==1]['file'].to_list(), out_dir + '/validation/b3/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
